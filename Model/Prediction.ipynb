{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 31)\n",
      "torch.FloatTensor\n",
      "torch.Size([30, 2])\n"
     ]
    }
   ],
   "source": [
    "# 读取 TXT 文件\n",
    "file_path = r'..\\MoviesData\\dailyPredictData\\BoxingData.txt'\n",
    "data = np.loadtxt(file_path)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "#去掉电影名\n",
    "data = data[:,1:]\n",
    "tensor_data = torch.from_numpy(data).float()\n",
    "\n",
    "print(tensor_data.type())\n",
    "#（时间步，批量大小）\n",
    "tensor_data = tensor_data.T\n",
    "print(tensor_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "test_data_size = 10\n",
    "\n",
    "batch_size = tensor_data.shape[1]\n",
    "train_data = tensor_data[:-test_data_size]\n",
    "test_data = tensor_data[-test_data_size:]\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "tensor([[[-1.0000],\n",
      "         [-1.0000]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9812],\n",
      "         [-0.9812]],\n",
      "\n",
      "        [[ 1.0000],\n",
      "         [ 1.0000]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-1.0000],\n",
      "         [-1.0000]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9812],\n",
      "         [-0.9812]],\n",
      "\n",
      "        [[ 1.0000],\n",
      "         [ 1.0000]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]],\n",
      "\n",
      "        [[-0.9877],\n",
      "         [-0.9877]]])\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data)\n",
    "\n",
    "train_data_normalized = torch.from_numpy(train_data_normalized).float()\n",
    "print(train_data_normalized.type())\n",
    "\n",
    "train_data_normalized = train_data_normalized.unsqueeze(2)\n",
    "print(train_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(train_data_normalized, train_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[[-1.0000],\n",
       "           [-1.0000]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9812],\n",
       "           [-0.9812]],\n",
       "  \n",
       "          [[ 1.0000],\n",
       "           [ 1.0000]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]]]),\n",
       "  tensor([[[-0.9877],\n",
       "           [-0.9877]]])),\n",
       " (tensor([[[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9812],\n",
       "           [-0.9812]],\n",
       "  \n",
       "          [[ 1.0000],\n",
       "           [ 1.0000]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]]]),\n",
       "  tensor([[[-0.9877],\n",
       "           [-0.9877]]])),\n",
       " (tensor([[[-0.9812],\n",
       "           [-0.9812]],\n",
       "  \n",
       "          [[ 1.0000],\n",
       "           [ 1.0000]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]]]),\n",
       "  tensor([[[-0.9877],\n",
       "           [-0.9877]]])),\n",
       " (tensor([[[ 1.0000],\n",
       "           [ 1.0000]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]]]),\n",
       "  tensor([[[-1.],\n",
       "           [-1.]]])),\n",
       " (tensor([[[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-0.9877],\n",
       "           [-0.9877]],\n",
       "  \n",
       "          [[-1.0000],\n",
       "           [-1.0000]]]),\n",
       "  tensor([[[-0.9877],\n",
       "           [-0.9877]]]))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # 获取批量大小\n",
    "        batch_size = input_seq.size(1)\n",
    "        # 初始化隐藏状态和细胞状态，形状为 (num_layers, batch_size, hidden_layer_size)\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, batch_size, self.hidden_layer_size),\n",
    "            torch.zeros(1, batch_size, self.hidden_layer_size)\n",
    "        )\n",
    "        # 输入序列已经是 (时间步, 批量大小, 输入特征维度) 的形状，无需调整\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq, self.hidden_cell)\n",
    "        # 调整 LSTM 输出的形状，以便输入到全连接层\n",
    "        # lstm_out 的形状是 (时间步, 批量大小, 隐藏层维度)\n",
    "        # 调整为 (时间步 * 批量大小, 隐藏层维度)\n",
    "        lstm_out_reshaped = lstm_out.view(-1, self.hidden_layer_size)\n",
    "        # 通过全连接层得到预测结果\n",
    "        # predictions 的形状是 (时间步 * 批量大小, 输出维度)\n",
    "        predictions = self.linear(lstm_out_reshaped)\n",
    "        # 重新调整预测结果的形状为 (时间步, 批量大小, 输出维度)\n",
    "        predictions = predictions.view(input_seq.size(0), batch_size, -1)\n",
    "        # 返回每个批次最后一个时间步的预测结果\n",
    "        # 形状为 (批量大小, 输出维度)\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.11505309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1, 2, 1])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  26 loss: 0.01212941\n",
      "epoch:  51 loss: 0.00068274\n",
      "epoch:  76 loss: 0.00048626\n",
      "epoch: 101 loss: 0.00027870\n",
      "epoch: 126 loss: 0.00012017\n",
      "epoch: 149 loss: 0.0001628689\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    " \n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(batch_size, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(batch_size, 1, model.hidden_layer_size))\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    " \n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    " \n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
